{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üöÄ Multimodal Agents Workshop - Simplified Version\n\nThis workshop demonstrates how to build **multimodal AI agents** using the new `pymongo-voyageai-multimodal` library, which dramatically simplifies the integration of:\n\n- **MongoDB Atlas Vector Search**\n- **Voyage AI's `voyage-multimodal-3` embeddings**\n- **Google Gemini 2.0 for AI agent capabilities**\n- **AWS S3 for document storage (Optional)**\n\n## üéØ What's Different?\n\nThe `pymongo-voyageai-multimodal` library handles:\n- ‚úÖ Automatic PDF processing from URLs (no S3 required!)\n- ‚úÖ Embedding generation with Voyage AI\n- ‚úÖ Vector index management\n- ‚úÖ Simplified similarity search\n- üéÅ **BONUS**: S3 integration for advanced use cases (optional)\n\n## üìã Prerequisites\n\n### Required Dependencies:\n```bash\npip install pymongo-voyageai-multimodal google-generativeai tqdm python-dotenv\n```\n\n### Required Environment Variables (create a `.env` file):\n```\n# Required for core functionality\nMONGODB_ATLAS_CONNECTION_STRING=your_mongodb_uri\nVOYAGEAI_API_KEY=your_voyage_api_key\nGOOGLE_API_KEY=your_gemini_api_key\n```\n\n### Optional Environment Variables:\n```\n# Only needed for S3 features (completely optional!)\nS3_BUCKET_NAME=your_s3_bucket\n```\n\n## üí° Core Workshop vs Optional S3 Features\n\n### ‚úÖ Works Without S3:\n- Direct PDF URL processing (e.g., arXiv papers)\n- All vector search functionality\n- AI agent creation\n- Text document processing\n- All learning objectives\n\n### üéÅ S3 Bonus Features:\n- Load PDFs from private S3 buckets\n- Process documents stored in AWS\n- Enterprise-grade document storage\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pymongo_voyageai_multimodal import PyMongoVoyageAI\n\n# Check required environment variables\nrequired_vars = [\"MONGODB_ATLAS_CONNECTION_STRING\", \"VOYAGEAI_API_KEY\"]\noptional_vars = [\"S3_BUCKET_NAME\"]  # S3 is optional!\n\nmissing_required = [var for var in required_vars if not os.getenv(var)]\nmissing_optional = [var for var in optional_vars if not os.getenv(var)]\n\nif missing_required:\n    show_error(f\"Missing REQUIRED environment variables: {missing_required}\")\n    show_warning(\"Please set these in your .env file\")\nelse:\n    show_success(\"All required environment variables found!\")\n    \n    if missing_optional:\n        show_warning(f\"Optional variables not set: {missing_optional}\")\n        show_info(\"S3 functionality will be disabled, but you can still use direct URL fetching!\")\n    \n    # Initialize the client (S3 is optional)\n    client = PyMongoVoyageAI.from_connection_string(\n        connection_string=os.environ[\"MONGODB_ATLAS_CONNECTION_STRING\"],\n        database_name=\"multimodal_lab_simplified\",\n        collection_name=\"documents\",\n        s3_bucket_name=os.environ.get(\"S3_BUCKET_NAME\", None),  # Optional\n        voyageai_api_key=os.environ[\"VOYAGEAI_API_KEY\"]\n    )\n    \n    show_success(\"PyMongoVoyageAI client initialized successfully!\")\n    show_info(f\"Database: multimodal_lab_simplified\")\n    show_info(f\"Collection: documents\")\n    \n    if os.environ.get(\"S3_BUCKET_NAME\"):\n        show_info(f\"S3 Bucket: {os.environ['S3_BUCKET_NAME']} (enabled)\")\n    else:\n        show_info(\"S3 Support: Disabled (using direct URL fetching only)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Process a research paper from a direct URL (no S3 required!)\npdf_url = \"https://arxiv.org/pdf/2501.12948\"  # DeepSeek R1 paper\n\nshow_info(f\"Processing PDF from: {pdf_url}\")\nshow_success(\"Direct URL fetching - No S3 required!\")\nshow_info(\"This will automatically:\")\nshow_info(\"‚Ä¢ Download the PDF from the URL\")\nshow_info(\"‚Ä¢ Extract pages as images\")\nshow_info(\"‚Ä¢ Generate embeddings with voyage-multimodal-3\")\nshow_info(\"‚Ä¢ Store in MongoDB with vector indexes\")\n\ntry:\n    # Process PDF from direct URL (works without S3!)\n    images = client.url_to_images(pdf_url)\n    \n    show_success(f\"Extracted {len(images)} pages from PDF\")\n    \n    # Generate IDs for each page\n    ids = [f\"deepseek_page_{i+1}\" for i in range(len(images))]\n    \n    # Add documents to MongoDB with embeddings\n    client.add_documents(documents=images, ids=ids)\n    \n    show_success(f\"Successfully indexed {len(images)} document pages!\")\n    show_info(\"‚úÖ No S3 bucket required for this operation!\")\n    \nexcept Exception as e:\n    show_error(f\"Failed to process PDF: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo_voyageai_multimodal import PyMongoVoyageAI\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = [\"MONGODB_ATLAS_CONNECTION_STRING\", \"S3_BUCKET_NAME\", \"VOYAGEAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    show_error(f\"Missing environment variables: {missing_vars}\")\n",
    "    show_warning(\"Please set these in your .env file\")\n",
    "else:\n",
    "    # Initialize the client\n",
    "    client = PyMongoVoyageAI.from_connection_string(\n",
    "        connection_string=os.environ[\"MONGODB_ATLAS_CONNECTION_STRING\"],\n",
    "        database_name=\"multimodal_lab_simplified\",\n",
    "        collection_name=\"documents\",\n",
    "        s3_bucket_name=os.environ[\"S3_BUCKET_NAME\"],\n",
    "        voyageai_api_key=os.environ[\"VOYAGEAI_API_KEY\"]\n",
    "    )\n",
    "    \n",
    "    show_success(\"PyMongoVoyageAI client initialized successfully!\")\n",
    "    show_info(f\"Database: multimodal_lab_simplified\")\n",
    "    show_info(f\"Collection: documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process and Index Documents\n",
    "\n",
    "The library automatically:\n",
    "- Downloads PDFs from URLs\n",
    "- Extracts images from PDF pages\n",
    "- Generates multimodal embeddings\n",
    "- Stores documents in MongoDB with vector indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a research paper\n",
    "pdf_url = \"https://arxiv.org/pdf/2501.12948\"  # DeepSeek R1 paper\n",
    "\n",
    "show_info(f\"Processing PDF from: {pdf_url}\")\n",
    "show_info(\"This will automatically:\")\n",
    "show_info(\"‚Ä¢ Download the PDF\")\n",
    "show_info(\"‚Ä¢ Extract pages as images\")\n",
    "show_info(\"‚Ä¢ Generate embeddings with voyage-multimodal-3\")\n",
    "show_info(\"‚Ä¢ Store in MongoDB with vector indexes\")\n",
    "\n",
    "try:\n",
    "    # Process PDF and get document images\n",
    "    images = client.url_to_images(pdf_url)\n",
    "    \n",
    "    show_success(f\"Extracted {len(images)} pages from PDF\")\n",
    "    \n",
    "    # Generate IDs for each page\n",
    "    ids = [f\"deepseek_page_{i+1}\" for i in range(len(images))]\n",
    "    \n",
    "    # Add documents to MongoDB with embeddings\n",
    "    client.add_documents(documents=images, ids=ids)\n",
    "    \n",
    "    show_success(f\"Successfully indexed {len(images)} document pages!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    show_error(f\"Failed to process PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Step 6: Optional - Add Documents from S3\n# This section only works if you have S3 configured\n\nshow_info(\"üì¶ S3 Integration (Optional Advanced Feature)\")\n\nif os.environ.get(\"S3_BUCKET_NAME\"):\n    show_success(\"S3 bucket configured! You can use S3 features.\")\n    \n    # Example: Load documents from S3\n    # Uncomment and modify with your S3 paths\n    \n    # s3_pdf_path = f\"s3://{os.environ['S3_BUCKET_NAME']}/path/to/document.pdf\"\n    # \n    # try:\n    #     show_info(f\"Processing PDF from S3: {s3_pdf_path}\")\n    #     \n    #     # Process PDF from S3\n    #     s3_images = client.url_to_images(s3_pdf_path)\n    #     \n    #     # Add with custom IDs\n    #     s3_ids = [f\"s3_doc_page_{i+1}\" for i in range(len(s3_images))]\n    #     client.add_documents(documents=s3_images, ids=s3_ids)\n    #     \n    #     show_success(f\"Added {len(s3_images)} pages from S3!\")\n    # except Exception as e:\n    #     show_error(f\"S3 processing failed: {e}\")\n    \n    show_info(\"üí° S3 URLs work the same as direct URLs: client.url_to_images('s3://bucket/file.pdf')\")\nelse:\n    show_warning(\"S3_BUCKET_NAME not configured - S3 features disabled\")\n    show_info(\"‚úÖ Don't worry! The workshop works perfectly without S3\")\n    show_info(\"‚Ä¢ Direct URL fetching works for any public PDF\")\n    show_info(\"‚Ä¢ You can still process local files by uploading them first\")\n    show_info(\"‚Ä¢ All core functionality remains available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search functionality\n",
    "test_queries = [\n",
    "    \"What is the Pass@1 accuracy on MATH500?\",\n",
    "    \"Show me performance benchmarks\",\n",
    "    \"Architecture diagrams\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    show_info(f\"\\nüîç Searching for: {query}\")\n",
    "    \n",
    "    try:\n",
    "        # Perform similarity search\n",
    "        results = client.similarity_search(query=query, k=2)\n",
    "        \n",
    "        show_success(f\"Found {len(results)} relevant documents\")\n",
    "        \n",
    "        for i, doc in enumerate(results):\n",
    "            show_info(f\"Result {i+1}: {doc.get('id', 'Unknown')} (Score: {doc.get('score', 0):.4f})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        show_error(f\"Search failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build an AI Agent with Gemini\n",
    "\n",
    "Now let's create an AI agent that uses the multimodal search to answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.genai.types import FunctionCall\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# Initialize Gemini\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    show_error(\"GOOGLE_API_KEY not found in environment\")\n",
    "else:\n",
    "    gemini_client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "    LLM = \"gemini-2.0-flash\"\n",
    "    show_success(f\"Gemini client initialized with model: {LLM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_search_tool(query: str, num_results: int = 2) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Search for relevant documents using multimodal embeddings.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language search query\n",
    "        num_results: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of document dictionaries with content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        show_info(f\"üîç Searching for: {query}\")\n",
    "        \n",
    "        # Use the simplified search API\n",
    "        results = client.similarity_search(query=query, k=num_results)\n",
    "        \n",
    "        show_success(f\"Found {len(results)} relevant documents\")\n",
    "        \n",
    "        # Extract document content\n",
    "        documents = []\n",
    "        for result in results:\n",
    "            doc_info = {\n",
    "                'id': result.get('id', 'Unknown'),\n",
    "                'score': result.get('score', 0),\n",
    "                'content': result.get('inputs', {})  # This contains the image data\n",
    "            }\n",
    "            documents.append(doc_info)\n",
    "            \n",
    "        return documents\n",
    "        \n",
    "    except Exception as e:\n",
    "        show_error(f\"Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Define function declaration for Gemini\n",
    "search_declaration = {\n",
    "    \"name\": \"multimodal_search_tool\",\n",
    "    \"description\": \"Search for relevant documents using multimodal embeddings\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Natural language search query\"\n",
    "            },\n",
    "            \"num_results\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Number of results to return\",\n",
    "                \"default\": 2\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "show_success(\"Multimodal search tool defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gemini configuration with tools\n",
    "tools = types.Tool(function_declarations=[search_declaration])\n",
    "tools_config = types.GenerateContentConfig(tools=[tools], temperature=0.0)\n",
    "\n",
    "def multimodal_agent(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    AI agent that uses multimodal search to answer questions.\n",
    "    \n",
    "    Args:\n",
    "        user_query: User's question\n",
    "        \n",
    "    Returns:\n",
    "        Agent's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        show_info(f\"ü§ñ Processing query: {user_query}\")\n",
    "        \n",
    "        # Step 1: Decide if we need to search\n",
    "        system_prompt = \"\"\"You are an AI assistant with access to a multimodal document search tool.\n",
    "        Decide if you need to search for information to answer the user's question.\n",
    "        If yes, call the search tool with an appropriate query.\"\"\"\n",
    "        \n",
    "        # Get tool decision from Gemini\n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=LLM,\n",
    "            contents=[system_prompt, user_query],\n",
    "            config=tools_config\n",
    "        )\n",
    "        \n",
    "        # Check if tool was called\n",
    "        retrieved_docs = []\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "            for part in response.candidates[0].content.parts:\n",
    "                if hasattr(part, 'function_call') and part.function_call:\n",
    "                    if part.function_call.name == \"multimodal_search_tool\":\n",
    "                        show_info(\"üõ†Ô∏è Agent is searching for relevant documents...\")\n",
    "                        # Execute the search\n",
    "                        search_results = multimodal_search_tool(**part.function_call.args)\n",
    "                        retrieved_docs.extend(search_results)\n",
    "        \n",
    "        # Step 2: Generate final answer\n",
    "        if retrieved_docs:\n",
    "            context = f\"Based on the following retrieved documents:\\n\"\n",
    "            for doc in retrieved_docs:\n",
    "                context += f\"\\n- Document {doc['id']} (relevance: {doc['score']:.3f})\"\n",
    "            \n",
    "            final_prompt = f\"\"\"{context}\n",
    "            \n",
    "            Answer this question: {user_query}\n",
    "            \n",
    "            Base your answer only on the retrieved documents. If the information isn't available, say so.\"\"\"\n",
    "        else:\n",
    "            final_prompt = f\"Answer this question based on your general knowledge: {user_query}\"\n",
    "        \n",
    "        # Generate final response\n",
    "        final_response = gemini_client.models.generate_content(\n",
    "            model=LLM,\n",
    "            contents=[final_prompt],\n",
    "            config=types.GenerateContentConfig(temperature=0.0)\n",
    "        )\n",
    "        \n",
    "        return final_response.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        show_error(f\"Agent failed: {e}\")\n",
    "        return \"I apologize, but I encountered an error while processing your question.\"\n",
    "\n",
    "show_success(\"Multimodal agent created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test the Multimodal Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with various queries\n",
    "test_questions = [\n",
    "    \"What is the Pass@1 accuracy of DeepSeek R1 on the MATH500 benchmark?\",\n",
    "    \"What are the main architectural components?\",\n",
    "    \"How does the model perform on coding tasks?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    show_info(f\"\\n‚ùì Question: {question}\")\n",
    "    \n",
    "    answer = multimodal_agent(question)\n",
    "    \n",
    "    show_success(\"ü§ñ Agent Response:\")\n",
    "    display(HTML(f'<div style=\"background-color:#f5f5f5;padding:15px;border-radius:5px;margin:10px 0;\">{answer}</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Advanced - Add Documents from S3\n",
    "\n",
    "The library also supports loading documents directly from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load documents from S3\n",
    "# Uncomment and modify with your S3 paths\n",
    "\n",
    "# s3_pdf_path = \"s3://your-bucket/path/to/document.pdf\"\n",
    "# \n",
    "# try:\n",
    "#     # Process PDF from S3\n",
    "#     s3_images = client.url_to_images(s3_pdf_path)\n",
    "#     \n",
    "#     # Add with custom IDs\n",
    "#     s3_ids = [f\"s3_doc_page_{i+1}\" for i in range(len(s3_images))]\n",
    "#     client.add_documents(documents=s3_images, ids=s3_ids)\n",
    "#     \n",
    "#     show_success(f\"Added {len(s3_images)} pages from S3!\")\n",
    "# except Exception as e:\n",
    "#     show_error(f\"S3 processing failed: {e}\")\n",
    "\n",
    "show_info(\"S3 integration example - uncomment to use with your S3 bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Adding Text Documents\n",
    "\n",
    "The library also supports text documents alongside images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo_voyageai_multimodal import TextDocument\n",
    "\n",
    "# Create text documents\n",
    "text_docs = [\n",
    "    TextDocument(\n",
    "        text=\"DeepSeek R1 is a state-of-the-art language model with strong reasoning capabilities.\",\n",
    "        metadata={\"source\": \"summary\", \"type\": \"overview\"}\n",
    "    ),\n",
    "    TextDocument(\n",
    "        text=\"The model achieves 97.3% Pass@1 accuracy on MATH500 benchmark.\",\n",
    "        metadata={\"source\": \"benchmark\", \"type\": \"performance\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add text documents\n",
    "text_ids = [\"text_summary_1\", \"text_benchmark_1\"]\n",
    "\n",
    "try:\n",
    "    client.add_documents(documents=text_docs, ids=text_ids)\n",
    "    show_success(f\"Added {len(text_docs)} text documents!\")\n",
    "except Exception as e:\n",
    "    show_error(f\"Failed to add text documents: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Workshop Summary\n",
    "\n",
    "### What We've Built\n",
    "\n",
    "Using the `pymongo-voyageai-multimodal` library, we've created:\n",
    "\n",
    "1. **Automatic Document Processing**: PDFs ‚Üí Images ‚Üí Embeddings ‚Üí MongoDB\n",
    "2. **Simplified Vector Search**: Natural language queries without manual embedding\n",
    "3. **Multimodal AI Agent**: Gemini-powered agent with document retrieval\n",
    "4. **S3 Integration**: Direct document loading from cloud storage\n",
    "5. **Mixed Content**: Support for both images and text documents\n",
    "\n",
    "### Key Advantages\n",
    "\n",
    "- ‚úÖ **Minimal Code**: ~10x less code than manual implementation\n",
    "- ‚úÖ **Automatic Indexing**: No manual vector index creation\n",
    "- ‚úÖ **Built-in S3**: Cloud storage integration out of the box\n",
    "- ‚úÖ **Type Safety**: Structured document types (TextDocument, ImageDocument)\n",
    "- ‚úÖ **Production Ready**: Handles errors, retries, and edge cases\n",
    "\n",
    "### Limitations to Consider\n",
    "\n",
    "- ‚ùó **Static Datasets**: Best for read-heavy workloads\n",
    "- üîó **Voyage AI Only**: Currently limited to `voyage-multimodal-3`\n",
    "- üóÑÔ∏è **AWS S3**: Cloud storage limited to S3 (for now)\n",
    "- üîÑ **No Live Sync**: Re-indexing required for updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (optional)\n",
    "# client.close()\n",
    "\n",
    "show_success(\"üéâ Workshop completed successfully!\")\n",
    "show_info(\"You've built a multimodal AI agent with minimal code using pymongo-voyageai-multimodal!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}